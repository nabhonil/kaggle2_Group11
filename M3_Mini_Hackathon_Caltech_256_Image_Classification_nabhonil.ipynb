{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabhonil/kaggle2_Group11/blob/main/M3_Mini_Hackathon_Caltech_256_Image_Classification_nabhonil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM2cr8mbfwEA"
      },
      "source": [
        "### Objective:\n",
        "To classify images in the Caltech-256 dataset, which is an improvement over Caltech-101 dataset using a Convolutional Neural Network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-uLJvizgCBf"
      },
      "source": [
        "### Problem Statement\n",
        "To build and implement a Convolutional Neural Network model to classify images in the Caltech-256 dataset.\n",
        "\n",
        "At the end of this competition, you will be able to:\n",
        "\n",
        "* Load and extract features of images available in the Caltech-256 dataset using ImageDataGenerator\n",
        "\n",
        "* Build convolutional neural networks using either Keras or PyTorch deep learning libraries\n",
        "\n",
        "* Use the pre-trained models using either Keras or PyTorch deep learning libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdYmy-tJgURN"
      },
      "source": [
        "### Description:\n",
        "Caltech-256 is an object recognition dataset containing approximately 30,000 real-world images, of different sizes, spanning 256 classes (256 object classes and an additional clutter class). Each class is represented by at least 80 images. The dataset is a superset of the Caltech-101 dataset.\n",
        "\n",
        "Here is a handy link to Kaggle's competition documentation (https://www.kaggle.com/docs/competitions), which includes, among other things, instructions on submitting predictions (https://www.kaggle.com/docs/competitions#making-a-submission)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8OapRtHgLnU"
      },
      "source": [
        "### Instructions for downloading train and test data are as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO2jS73oLnCR"
      },
      "source": [
        "### 1. Create an API key in Kaggle.\n",
        "\n",
        "To do this, go to the competition site on Kaggle at https://www.kaggle.com/t/185418aa7ed24db3b98ed851a4db2b41 and click on user then click on your profile as shown below. Click Account.\n",
        "\n",
        "![alt text](https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Capture-NLP.PNG)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkzGffHdbwX2"
      },
      "source": [
        "### 2. Next, scroll down to the API access section and click on **Create New Token** to download an API key (kaggle.json).\n",
        "\n",
        "![alt text](https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Capture-NLP_1.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtETuXx8b-OC"
      },
      "source": [
        "### 3. Upload your kaggle.json file using the following snippet in a code cell:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1pfXBDxWl0Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "9512a3a2-f7e6-4d91-9526-886aed79f63e"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-30f03e3c-ceb5-4258-bd2a-b848d43cae68\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-30f03e3c-ceb5-4258-bd2a-b848d43cae68\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"nabhonilsinha\",\"key\":\"7fe14635be9bc787e64ba5ea1d696511\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCV_T6MMW4eX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c275022-e658-4214-b585-69d66dbef9f7"
      },
      "source": [
        "#If successfully uploaded in the above step, the 'ls' command here should display the kaggle.json file.\n",
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbukdzJ6cE32"
      },
      "source": [
        "### 4. Install the Kaggle API using the following command\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMj1n1MJcqzN"
      },
      "source": [
        "!pip install -U -q kaggle==1.5.8"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vpy9P1nchhd"
      },
      "source": [
        "### 5. Move the kaggle.json file into ~/.kaggle, which is where the API client expects your token to be located:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQbPsDOLZ0b4"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BenAWlpI73sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ce13ac-ffb4-4cf8-8ae9-33c4b1f92857"
      },
      "source": [
        "#Execute the following command to verify whether the kaggle.json is stored in the appropriate location: ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm2jGsCradOS"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json #run this command to ensure your Kaggle API token is secure on colab"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32unPZKzdI72"
      },
      "source": [
        "### 6. Now download the Test Data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppuy5gRKHFwv"
      },
      "source": [
        "**NOTE: If you get a '403 - Not Found' error after running the cell below, it is most likely that the user (whose kaggle.json is uploaded above) has not 'accepted' the rules of the competition and therefore has 'not joined' the competition.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41-ETZCE_A1j"
      },
      "source": [
        "If you encounter **401-unauthorised** download latest **kaggle.json** by repeating steps 1 & 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY40TmgfHq0s"
      },
      "source": [
        "#If you get a forbidden link, you have most likely not joined the competition.\n",
        "!kaggle competitions download -c classification-of-caltech-256-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip classification-of-caltech-256-images"
      ],
      "metadata": {
        "id": "5VmllhW5ENRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI_uUJyfOAHr"
      },
      "source": [
        "### 7. Download the Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8efM3KoBOLiV"
      },
      "source": [
        "%%capture\n",
        "!wget https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Caltech_256_Train.zip\n",
        "\n",
        "!unzip \"Caltech_256_Train.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BQEA97zTlTa"
      },
      "source": [
        "## Grading = 10 Marks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOUR CODING STARTS FROM HERE"
      ],
      "metadata": {
        "id": "QeKon2vruI_c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import Required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG52PDGENRgN"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53g0zVbjRV7K"
      },
      "source": [
        "### **Stage 1:** Data Loading and preprocessing of Images (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYSjwlcSGJq1"
      },
      "source": [
        "#### Analyze the shape of images and distribution of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_FC0knCfeFD"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdQY-dzZeqWm"
      },
      "source": [
        "#### Visualize the sample images of each class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCgAcqdGewsb"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkOr1nhNT5yD"
      },
      "source": [
        "### **Stage 2:** Build and train the CNN model using Keras/Pytorch (5 points)\n",
        "\n",
        "You can train the CNN model and Pre-trained model and then compare the model performance on the kaggle testset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjGEBM5BFeS8"
      },
      "source": [
        "### Transfer learning\n",
        "\n",
        "Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem.\n",
        "\n",
        "A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task.\n",
        "\n",
        "The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use the pre-trained models\n",
        "\n",
        "* Load the pre-trained model\n",
        "* Train and evaluate the images"
      ],
      "metadata": {
        "id": "_1ZKm2M2FeTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "RHP1TsTFbUwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-O0Jx99UhmI"
      },
      "source": [
        "###   **Stage 3**: Evaluate the Model and get model predictions on the Kaggle testset (2 Points)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Sw9qtXxaahOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBIA1sbLByIL"
      },
      "source": [
        "### Report Analysis\n",
        "\n",
        "- Compare the accuracies for the Pre-trained vs CNN models\n",
        "- What process was followed to tune the hyperparameters?\n",
        "- Plot the confusion matrix in terms of the misclassifications"
      ]
    }
  ]
}
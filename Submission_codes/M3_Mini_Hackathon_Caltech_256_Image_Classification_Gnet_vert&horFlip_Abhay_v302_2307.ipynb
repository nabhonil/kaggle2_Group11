{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM2cr8mbfwEA"
   },
   "source": [
    "### Objective:\n",
    "To classify images in the Caltech-256 dataset, which is an improvement over Caltech-101 dataset using a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-uLJvizgCBf"
   },
   "source": [
    "### Problem Statement\n",
    "To build and implement a Convolutional Neural Network model to classify images in the Caltech-256 dataset.\n",
    "\n",
    "At the end of this competition, you will be able to:\n",
    "\n",
    "* Load and extract features of images available in the Caltech-256 dataset using ImageDataGenerator\n",
    "\n",
    "* Build convolutional neural networks using either Keras or PyTorch deep learning libraries\n",
    "\n",
    "* Use the pre-trained models using either Keras or PyTorch deep learning libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdYmy-tJgURN"
   },
   "source": [
    "### Description:\n",
    "Caltech-256 is an object recognition dataset containing approximately 30,000 real-world images, of different sizes, spanning 256 classes (256 object classes and an additional clutter class). Each class is represented by at least 80 images. The dataset is a superset of the Caltech-101 dataset.\n",
    "\n",
    "Here is a handy link to Kaggle's competition documentation (https://www.kaggle.com/docs/competitions), which includes, among other things, instructions on submitting predictions (https://www.kaggle.com/docs/competitions#making-a-submission)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8OapRtHgLnU"
   },
   "source": [
    "### Instructions for downloading train and test data are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO2jS73oLnCR"
   },
   "source": [
    "### 1. Create an API key in Kaggle.\n",
    "\n",
    "To do this, go to the competition site on Kaggle at https://www.kaggle.com/t/185418aa7ed24db3b98ed851a4db2b41 and click on user then click on your profile as shown below. Click Account.\n",
    "\n",
    "![alt text](https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Capture-NLP.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkzGffHdbwX2"
   },
   "source": [
    "### 2. Next, scroll down to the API access section and click on **Create New Token** to download an API key (kaggle.json).\n",
    "\n",
    "![alt text](https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Capture-NLP_1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtETuXx8b-OC"
   },
   "source": [
    "### 3. Upload your kaggle.json file using the following snippet in a code cell:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "-1pfXBDxWl0Y",
    "outputId": "de3f25e1-83fc-49be-b36b-5d9810b81bfb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCV_T6MMW4eX",
    "outputId": "2cf01bcd-0fd3-45fb-f138-2ce302669e21"
   },
   "outputs": [],
   "source": [
    "#If successfully uploaded in the above step, the 'ls' command here should display the kaggle.json file.\n",
    "# %ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbukdzJ6cE32"
   },
   "source": [
    "### 4. Install the Kaggle API using the following command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dMj1n1MJcqzN"
   },
   "outputs": [],
   "source": [
    "# !pip install -U -q kaggle==1.5.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Vpy9P1nchhd"
   },
   "source": [
    "### 5. Move the kaggle.json file into ~/.kaggle, which is where the API client expects your token to be located:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yQbPsDOLZ0b4"
   },
   "outputs": [],
   "source": [
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BenAWlpI73sm",
    "outputId": "ae6421ba-5f72-4ddf-a3ba-d89648c0a378"
   },
   "outputs": [],
   "source": [
    "#Execute the following command to verify whether the kaggle.json is stored in the appropriate location: ~/.kaggle/kaggle.json\n",
    "# !ls ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vm2jGsCradOS"
   },
   "outputs": [],
   "source": [
    "# !chmod 600 /root/.kaggle/kaggle.json #run this command to ensure your Kaggle API token is secure on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32unPZKzdI72"
   },
   "source": [
    "### 6. Now download the Test Data from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppuy5gRKHFwv"
   },
   "source": [
    "**NOTE: If you get a '403 - Not Found' error after running the cell below, it is most likely that the user (whose kaggle.json is uploaded above) has not 'accepted' the rules of the competition and therefore has 'not joined' the competition.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41-ETZCE_A1j"
   },
   "source": [
    "If you encounter **401-unauthorised** download latest **kaggle.json** by repeating steps 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TY40TmgfHq0s",
    "outputId": "cce29c08-1acb-47da-a445-edeb62d39671"
   },
   "outputs": [],
   "source": [
    "#If you get a forbidden link, you have most likely not joined the competition.\n",
    "# !kaggle competitions download -c classification-of-caltech-256-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VmllhW5ENRr",
    "outputId": "369968e0-ca97-4f6f-b974-76a2d89bcff4"
   },
   "outputs": [],
   "source": [
    "# !mkdir /content/Kaggle2Test\n",
    "# !unzip classification-of-caltech-256-images -d /content/Kaggle2Test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fZrpDsz83xmJ"
   },
   "outputs": [],
   "source": [
    "# !mkdir Kaggle2Test/test\n",
    "# !mv test/* Kaggle2Test/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MI_uUJyfOAHr"
   },
   "source": [
    "### 7. Download the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8efM3KoBOLiV"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !wget https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Caltech_256_Train.zip\n",
    "\n",
    "# !unzip \"Caltech_256_Train.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BQEA97zTlTa"
   },
   "source": [
    "## Grading = 10 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeKon2vruI_c"
   },
   "source": [
    "## YOUR CODING STARTS FROM HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abstract-stocks"
   },
   "source": [
    "### Import Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YG52PDGENRgN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhay\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,shutil,glob,PIL\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53g0zVbjRV7K"
   },
   "source": [
    "### **Stage 1:** Data Loading and preprocessing of Images (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYSjwlcSGJq1"
   },
   "source": [
    "#### Analyze the shape of images and distribution of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BN8LigRXeR4m"
   },
   "source": [
    "**The below two cells were run with transform without normalization to get appropriate mean and standard deviation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NzY4BnX4ePoO"
   },
   "outputs": [],
   "source": [
    "# mean = 0.0\n",
    "# for img, _ in train_data:\n",
    "#     mean += img.mean([1,2])\n",
    "# mean = mean/len(train_data)\n",
    "# print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "efBKujnJePoP"
   },
   "outputs": [],
   "source": [
    "# sumel = 0.0\n",
    "# countel = 0\n",
    "# for img, _ in train_data:\n",
    "#     img = (img - mean.unsqueeze(1).unsqueeze(1))**2\n",
    "#     sumel += img.sum([1, 2])\n",
    "#     countel += torch.numel(img[0])\n",
    "# std = torch.sqrt(sumel/countel)\n",
    "# print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Z_FC0knCfeFD"
   },
   "outputs": [],
   "source": [
    "# Normalize with mean and std\n",
    "# train_transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.4839, 0.4528, 0.3962), (0.2702, 0.2655, 0.2745))])\n",
    "# train_transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "# transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor(), transforms.Normalize((0.5503, 0.5315, 0.5028), (0.3162, 0.3125, 0.3263))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oTFhZyeviUd8"
   },
   "outputs": [],
   "source": [
    "# Define train and test transforms for data preprocessing and image augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4839, 0.4528, 0.3962), (0.2702, 0.2655, 0.2745))])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4839, 0.4528, 0.3962), (0.2702, 0.2655, 0.2745))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "T6aeOLfgIZy3"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lc-ERQYaITV_"
   },
   "source": [
    "**We will be adjusting these values 224 224 after calculating mean and std dev. later on.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BzVnVYkxBK7C"
   },
   "outputs": [],
   "source": [
    "# Loading the train set file\n",
    "train_data_folder = \"./classification-of-caltech-256-images/train\" # Train directory for loading images\n",
    "total_dataset = datasets.ImageFolder(root=train_data_folder, transform=train_transform)\n",
    "# train_data = datasets.ImageFolder(root=train_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "onQwL8FUbaq9"
   },
   "outputs": [],
   "source": [
    "# splitting between train and Validation set\n",
    "train_size = int(0.9 * len(total_dataset))  # 90% for training\n",
    "val_size = len(total_dataset) - train_size  # Remaining 10% for validation\n",
    "train_data, val_data = torch.utils.data.random_split(total_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4C17yZSrbqn6"
   },
   "outputs": [],
   "source": [
    "#defiining train_batch_size\n",
    "train_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6RWIkIDscA3G"
   },
   "outputs": [],
   "source": [
    "# Create data loaders for training and validation\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=train_batch_size,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=train_batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JRRJgkJYBPz6"
   },
   "outputs": [],
   "source": [
    "# Loading the test set file\n",
    "test_data_folder = \"./classification-of-caltech-256-images/test_images\" # Test directory for loading images\n",
    "test_data = datasets.ImageFolder(root=test_data_folder, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YekVS5WqjWkK",
    "outputId": "c56629a7-50ec-4ebe-a3f6-dede283fd9eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001.ak47',\n",
       " '002.american-flag',\n",
       " '003.backpack',\n",
       " '004.baseball-bat',\n",
       " '005.baseball-glove',\n",
       " '006.basketball-hoop',\n",
       " '007.bat',\n",
       " '008.bathtub',\n",
       " '009.bear',\n",
       " '010.beer-mug',\n",
       " '011.billiards',\n",
       " '012.binoculars',\n",
       " '013.birdbath',\n",
       " '014.blimp',\n",
       " '015.bonsai-101',\n",
       " '016.boom-box',\n",
       " '017.bowling-ball',\n",
       " '018.bowling-pin',\n",
       " '019.boxing-glove',\n",
       " '020.brain-101',\n",
       " '021.breadmaker',\n",
       " '022.buddha-101',\n",
       " '023.bulldozer',\n",
       " '024.butterfly',\n",
       " '025.cactus',\n",
       " '026.cake',\n",
       " '027.calculator',\n",
       " '028.camel',\n",
       " '029.cannon',\n",
       " '030.canoe',\n",
       " '031.car-tire',\n",
       " '032.cartman',\n",
       " '033.cd',\n",
       " '034.centipede',\n",
       " '035.cereal-box',\n",
       " '036.chandelier-101',\n",
       " '037.chess-board',\n",
       " '038.chimp',\n",
       " '039.chopsticks',\n",
       " '040.cockroach',\n",
       " '041.coffee-mug',\n",
       " '042.coffin',\n",
       " '043.coin',\n",
       " '044.comet',\n",
       " '045.computer-keyboard',\n",
       " '046.computer-monitor',\n",
       " '047.computer-mouse',\n",
       " '048.conch',\n",
       " '049.cormorant',\n",
       " '050.covered-wagon',\n",
       " '051.cowboy-hat',\n",
       " '052.crab-101',\n",
       " '053.desk-globe',\n",
       " '054.diamond-ring',\n",
       " '055.dice',\n",
       " '056.dog',\n",
       " '057.dolphin-101',\n",
       " '058.doorknob',\n",
       " '059.drinking-straw',\n",
       " '060.duck',\n",
       " '061.dumb-bell',\n",
       " '062.eiffel-tower',\n",
       " '063.electric-guitar-101',\n",
       " '064.elephant-101',\n",
       " '065.elk',\n",
       " '066.ewer-101',\n",
       " '067.eyeglasses',\n",
       " '068.fern',\n",
       " '069.fighter-jet',\n",
       " '070.fire-extinguisher',\n",
       " '071.fire-hydrant',\n",
       " '072.fire-truck',\n",
       " '073.fireworks',\n",
       " '074.flashlight',\n",
       " '075.floppy-disk',\n",
       " '076.football-helmet',\n",
       " '077.french-horn',\n",
       " '078.fried-egg',\n",
       " '079.frisbee',\n",
       " '080.frog',\n",
       " '081.frying-pan',\n",
       " '082.galaxy',\n",
       " '083.gas-pump',\n",
       " '084.giraffe',\n",
       " '085.goat',\n",
       " '086.golden-gate-bridge',\n",
       " '087.goldfish',\n",
       " '088.golf-ball',\n",
       " '089.goose',\n",
       " '090.gorilla',\n",
       " '091.grand-piano-101',\n",
       " '092.grapes',\n",
       " '093.grasshopper',\n",
       " '094.guitar-pick',\n",
       " '095.hamburger',\n",
       " '096.hammock',\n",
       " '097.harmonica',\n",
       " '098.harp',\n",
       " '099.harpsichord',\n",
       " '100.hawksbill-101',\n",
       " '101.head-phones',\n",
       " '102.helicopter-101',\n",
       " '103.hibiscus',\n",
       " '104.homer-simpson',\n",
       " '105.horse',\n",
       " '106.horseshoe-crab',\n",
       " '107.hot-air-balloon',\n",
       " '108.hot-dog',\n",
       " '109.hot-tub',\n",
       " '110.hourglass',\n",
       " '111.house-fly',\n",
       " '112.human-skeleton',\n",
       " '113.hummingbird',\n",
       " '114.ibis-101',\n",
       " '115.ice-cream-cone',\n",
       " '116.iguana',\n",
       " '117.ipod',\n",
       " '118.iris',\n",
       " '119.jesus-christ',\n",
       " '120.joy-stick',\n",
       " '121.kangaroo-101',\n",
       " '122.kayak',\n",
       " '123.ketch-101',\n",
       " '124.killer-whale',\n",
       " '125.knife',\n",
       " '126.ladder',\n",
       " '127.laptop-101',\n",
       " '128.lathe',\n",
       " '129.leopards-101',\n",
       " '130.license-plate',\n",
       " '131.lightbulb',\n",
       " '132.light-house',\n",
       " '133.lightning',\n",
       " '134.llama-101',\n",
       " '135.mailbox',\n",
       " '136.mandolin',\n",
       " '137.mars',\n",
       " '138.mattress',\n",
       " '139.megaphone',\n",
       " '140.menorah-101',\n",
       " '141.microscope',\n",
       " '142.microwave',\n",
       " '143.minaret',\n",
       " '144.minotaur',\n",
       " '145.motorbikes-101',\n",
       " '146.mountain-bike',\n",
       " '147.mushroom',\n",
       " '148.mussels',\n",
       " '149.necktie',\n",
       " '150.octopus',\n",
       " '151.ostrich',\n",
       " '152.owl',\n",
       " '153.palm-pilot',\n",
       " '154.palm-tree',\n",
       " '155.paperclip',\n",
       " '156.paper-shredder',\n",
       " '157.pci-card',\n",
       " '158.penguin',\n",
       " '159.people',\n",
       " '160.pez-dispenser',\n",
       " '161.photocopier',\n",
       " '162.picnic-table',\n",
       " '163.playing-card',\n",
       " '164.porcupine',\n",
       " '165.pram',\n",
       " '166.praying-mantis',\n",
       " '167.pyramid',\n",
       " '168.raccoon',\n",
       " '169.radio-telescope',\n",
       " '170.rainbow',\n",
       " '171.refrigerator',\n",
       " '172.revolver-101',\n",
       " '173.rifle',\n",
       " '174.rotary-phone',\n",
       " '175.roulette-wheel',\n",
       " '176.saddle',\n",
       " '177.saturn',\n",
       " '178.school-bus',\n",
       " '179.scorpion-101',\n",
       " '180.screwdriver',\n",
       " '181.segway',\n",
       " '182.self-propelled-lawn-mower',\n",
       " '183.sextant',\n",
       " '184.sheet-music',\n",
       " '185.skateboard',\n",
       " '186.skunk',\n",
       " '187.skyscraper',\n",
       " '188.smokestack',\n",
       " '189.snail',\n",
       " '190.snake',\n",
       " '191.sneaker',\n",
       " '192.snowmobile',\n",
       " '193.soccer-ball',\n",
       " '194.socks',\n",
       " '195.soda-can',\n",
       " '196.spaghetti',\n",
       " '197.speed-boat',\n",
       " '198.spider',\n",
       " '199.spoon',\n",
       " '200.stained-glass',\n",
       " '201.starfish-101',\n",
       " '202.steering-wheel',\n",
       " '203.stirrups',\n",
       " '204.sunflower-101',\n",
       " '205.superman',\n",
       " '206.sushi',\n",
       " '207.swan',\n",
       " '208.swiss-army-knife',\n",
       " '209.sword',\n",
       " '210.syringe',\n",
       " '211.tambourine',\n",
       " '212.teapot',\n",
       " '213.teddy-bear',\n",
       " '214.teepee',\n",
       " '215.telephone-box',\n",
       " '216.tennis-ball',\n",
       " '217.tennis-court',\n",
       " '218.tennis-racket',\n",
       " '219.theodolite',\n",
       " '220.toaster',\n",
       " '221.tomato',\n",
       " '222.tombstone',\n",
       " '223.top-hat',\n",
       " '224.touring-bike',\n",
       " '225.tower-pisa',\n",
       " '226.traffic-light',\n",
       " '227.treadmill',\n",
       " '228.triceratops',\n",
       " '229.tricycle',\n",
       " '230.trilobite-101',\n",
       " '231.tripod',\n",
       " '232.t-shirt',\n",
       " '233.tuning-fork',\n",
       " '234.tweezer',\n",
       " '235.umbrella-101',\n",
       " '236.unicorn',\n",
       " '237.vcr',\n",
       " '238.video-projector',\n",
       " '239.washing-machine',\n",
       " '240.watch-101',\n",
       " '241.waterfall',\n",
       " '242.watermelon',\n",
       " '243.welding-mask',\n",
       " '244.wheelbarrow',\n",
       " '245.windmill',\n",
       " '246.wine-bottle',\n",
       " '247.xylophone',\n",
       " '248.yarmulke',\n",
       " '249.yo-yo',\n",
       " '250.zebra',\n",
       " '251.airplanes-101',\n",
       " '252.car-side-101',\n",
       " '253.faces-easy-101',\n",
       " '254.greyhound',\n",
       " '255.tennis-shoes',\n",
       " '256.toad',\n",
       " '257.clutter']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.classes\n",
    "total_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "JDMI9MDHBPwf"
   },
   "outputs": [],
   "source": [
    "# # Initializing batch size\n",
    "# batch_size = 64\n",
    "\n",
    "# # Loading the train dataset\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "la3vAIgDBPpv",
    "outputId": "e9338d96-e4a9-40d3-9f58-3d65b7535740"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a batches of images and labels\n",
    "train_images, train_labels = next(iter(train_loader))\n",
    "train_images.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2vZ0AO9nBPlS"
   },
   "outputs": [],
   "source": [
    "# labels Translator\n",
    "label_names = {v: k for k, v in total_dataset.class_to_idx.items()}\n",
    "# label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "QsfIUhmoBPhp"
   },
   "outputs": [],
   "source": [
    "# Create a grid of images along with their corresponding labels\n",
    "# L = 3\n",
    "# W = 3\n",
    "\n",
    "# fig, axes = plt.subplots(L, W, figsize = (10, 10))\n",
    "# axes = axes.reshape(-1)\n",
    "\n",
    "# for i in np.arange(0, L*W):\n",
    "#     axes[i].imshow(train_images[i].permute(1, 2, 0))\n",
    "#     axes[i].set_title(label_names[train_labels[i].item()])\n",
    "#     axes[i].axis('on')\n",
    "\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "quy6Ov3FBPdN"
   },
   "outputs": [],
   "source": [
    "# mean = 0.0\n",
    "# for img, _ in train_data:\n",
    "#     mean += img.mean([1,2])\n",
    "# mean = mean/len(train_data)\n",
    "# print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "aRJyw4xnBPZA"
   },
   "outputs": [],
   "source": [
    "# sumel = 0.0\n",
    "# countel = 0\n",
    "# for img, _ in train_data:\n",
    "#     img = (img - mean.unsqueeze(1).unsqueeze(1))**2\n",
    "#     sumel += img.sum([1, 2])\n",
    "#     countel += torch.numel(img[0])\n",
    "# std = torch.sqrt(sumel/countel)\n",
    "# print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "poU9n8u2BPR6"
   },
   "outputs": [],
   "source": [
    "# sum = 0\n",
    "# for label in train_data.classes:\n",
    "#     num_img = len(train_data.targets[train_data.targets == train_data.class_to_idx[label]])\n",
    "#     print (num_img)\n",
    "# print (sum)\n",
    "\n",
    "num_classes = len(total_dataset.classes)\n",
    "dataset_size = len(total_dataset)\n",
    "classes = total_dataset.classes\n",
    "img_dict = {}\n",
    "for i in range(num_classes):\n",
    "    img_dict[classes[i]] = 0\n",
    "\n",
    "for i in range(dataset_size):\n",
    "    img, label = total_dataset[i]\n",
    "    img_dict[classes[label]] += 1\n",
    "\n",
    "# img_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krqjf7tIHlqg"
   },
   "source": [
    "**Our observation is all those minority classes we need to go for augmenting new samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJ9l-8dPBPJh",
    "outputId": "f8e806e1-a6ae-40ea-c15e-37b2f88132fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n"
     ]
    }
   ],
   "source": [
    "# No of Categories\n",
    "print(len(total_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XnXP8SJZe0Wf"
   },
   "outputs": [],
   "source": [
    "# total_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EysC9vCOP6A",
    "outputId": "fc91f9f4-dfdb-4683-ec93-949269a7c4da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXKWKI3feSN9",
    "outputId": "130ebfbc-659e-499c-dfd4-ead58b2e2b57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8163, 0.8247, 0.5298, 0.6299, 0.5405, 0.8889, 0.7547, 0.3448, 0.7843,\n",
       "        0.8511, 0.2878, 0.3704, 0.8163, 0.9302, 0.6557, 0.8791, 0.7692, 0.7921,\n",
       "        0.6452, 0.9639, 0.5634, 0.8247, 0.7273, 0.7143, 0.7018, 0.7547, 0.8000,\n",
       "        0.7273, 0.7767, 0.7692, 0.8889, 0.7921, 0.7843, 0.8000, 0.9195, 0.7547,\n",
       "        0.6667, 0.7273, 0.9412, 0.6452, 0.9195, 0.9195, 0.6452, 0.6612, 0.9412,\n",
       "        0.6015, 0.8511, 0.7767, 0.7547, 0.8247, 0.7018, 0.9412, 0.9756, 0.6780,\n",
       "        0.8163, 0.7843, 0.7547, 0.8602, 0.9639, 0.9195, 0.7843, 0.9639, 0.6557,\n",
       "        0.6107, 0.7921, 0.9639, 0.9639, 0.7273, 0.8081, 0.9524, 0.8081, 0.6780,\n",
       "        0.8000, 0.6957, 0.9639, 0.9524, 0.8696, 0.8889, 0.8081, 0.6897, 0.8421,\n",
       "        0.9877, 0.8421, 0.9524, 0.7143, 1.0000, 0.8602, 0.8163, 0.7273, 0.3774,\n",
       "        0.8421, 0.3980, 0.7143, 0.7692, 0.9302, 0.2807, 0.8989, 0.8000, 1.0000,\n",
       "        0.8602, 0.5797, 0.9091, 0.7207, 0.8247, 0.2963, 0.9195, 0.8989, 0.9412,\n",
       "        0.5128, 0.9412, 0.9524, 0.9524, 0.6897, 0.6667, 0.9091, 0.7477, 0.6612,\n",
       "        0.7407, 0.9195, 0.6154, 0.9756, 0.7767, 0.7207, 0.8791, 0.7921, 0.3306,\n",
       "        0.6250, 0.7619, 0.4211, 0.8791, 0.8696, 0.4211, 0.5882, 0.6723, 0.8602,\n",
       "        0.8602, 0.5128, 0.4167, 0.9302, 0.8989, 0.6838, 0.7477, 0.6154, 0.9756,\n",
       "        0.1003, 0.9756, 0.3960, 0.4598, 0.7767, 0.7207, 0.7339, 0.6667, 0.8602,\n",
       "        0.7767, 0.8696, 0.8333, 0.7619, 0.5369, 0.3828, 0.9639, 0.7767, 0.8791,\n",
       "        0.8889, 0.7921, 0.9091, 0.8696, 0.9302, 0.5714, 0.8696, 0.7843, 0.9524,\n",
       "        0.8081, 0.7547, 0.9524, 0.9639, 0.7273, 0.8333, 0.8163, 1.0000, 0.7843,\n",
       "        0.8000, 0.6667, 0.8000, 0.9524, 0.7767, 0.9877, 0.8421, 0.9091, 0.6723,\n",
       "        0.7143, 0.7207, 0.7143, 0.4598, 0.7143, 0.9195, 0.7692, 0.8000, 0.7407,\n",
       "        0.7619, 0.8000, 0.9877, 0.8247, 0.8791, 1.0000, 0.9195, 0.8163, 0.6957,\n",
       "        0.7339, 0.7843, 0.7207, 0.8421, 0.5882, 0.7921, 0.5755, 0.9524, 0.8163,\n",
       "        0.7619, 0.9877, 0.9524, 0.8511, 0.7767, 0.8791, 1.0000, 0.7273, 0.8889,\n",
       "        0.8081, 0.5442, 0.8421, 0.8421, 0.8511, 0.7143, 0.2235, 0.8000, 0.6557,\n",
       "        0.7018, 0.8247, 0.8889, 0.8247, 0.9524, 0.3980, 0.8421, 0.8602, 0.8889,\n",
       "        0.8791, 0.8791, 0.7921, 0.8696, 0.9524, 0.8000, 0.8333, 0.1000, 0.6897,\n",
       "        0.1839, 0.8421, 0.7767, 0.7407, 0.0967], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate class weights\n",
    "class_weights = torch.tensor([1.0] * num_classes)  # Initialize with equal weights\n",
    "\n",
    "# Calculate class frequencies\n",
    "class_counts = torch.bincount(torch.tensor(total_dataset.targets))\n",
    "total_samples = len(total_dataset)\n",
    "class_frequencies = class_counts.float() / total_samples\n",
    "\n",
    "# Update class weights based on class frequencies\n",
    "class_weights = 1.0 / class_frequencies\n",
    "\n",
    "# Normalize class weights\n",
    "class_weights /= torch.max(class_weights)\n",
    "class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Z15D5RloIi8",
    "outputId": "92606b91-2742-40b4-8960-f24fe44e6531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRH3c81gIF0H",
    "outputId": "fe6ee89d-0243-4111-87ed-9061891daa61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30607\n"
     ]
    }
   ],
   "source": [
    "# Number of training samples\n",
    "print(len(total_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRFg5oUyBO_2",
    "outputId": "026226b4-c5ff-45a1-8c2a-67abbb1701c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Size of one training image\n",
    "print(train_data[0][0].size(), val_data[0][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "VEA_l_jNBOzx",
    "outputId": "e6c7ca88-a571-401f-dc08-81f25e629ca0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'257.clutter'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(img_dict,key=img_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "usbPxHFPKC8f"
   },
   "outputs": [],
   "source": [
    "# print(img_dict.values())\n",
    "# total = sum(img_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3TIlsKoKDFU",
    "outputId": "7fcedf39-3f34-46a3-c5d2-3c1ce9c7d81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.12.1+cu116 CUDA: True\n"
     ]
    }
   ],
   "source": [
    "# To test whether GPU instance is present in the system of not.\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Using PyTorch version:', torch.__version__, 'CUDA:', use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckLKFtR3KDIj",
    "outputId": "31992d92-7f6d-45d2-9974-7980339c8755"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhay\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abhay\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogLeNet(\n",
      "  (conv1): BasicConv2d(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv2): BasicConv2d(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): BasicConv2d(\n",
      "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception3a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception3b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception4a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4c): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4d): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4e): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception5a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception5b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (aux1): None\n",
      "  (aux2): None\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=1024, out_features=257, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.googlenet(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "#model.softmax = nn.softmax()\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='CalTech-256-GoogleNet_v302_2107.pth'\n",
    "# PATH='CalTech-256-GoogleNet_v302_2307.pth'\n",
    "model_ft.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "C85LEWZeKDLq"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lVpIc9ZIELmi"
   },
   "outputs": [],
   "source": [
    "epsilon = 0.005  # Perturbation strength for FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "NMwER9i_g023"
   },
   "outputs": [],
   "source": [
    "train_accu = []     # Empty list for saving train accuracy\n",
    "train_losses = []   # Empty list for saving train losses\n",
    "val_accu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Bk3qQgcYKDOi"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  print('\\nEpoch : %d'%epoch)\n",
    "\n",
    "  model_ft.train()    # Initiate the model in training mode\n",
    "\n",
    "  running_loss = 0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  for data in tqdm(train_loader):\n",
    "\n",
    "    inputs,labels=data[0].to(device),data[1].to(device)   # Loading the input tensors into CUDA GPU\n",
    "    # print(inputs,labels)\n",
    "    # Generate adversarial examples using FGSM\n",
    "    # inputs.requires_grad = True\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model_ft(inputs)\n",
    "    loss = criterion(outputs,labels)  # Calculating the loss\n",
    "    loss.backward()                   # Back Propagation for calculaing gradients and adjusting weights\n",
    "\n",
    "    # Create perturbations based on the sign of gradients\n",
    "    # inputs_grad = inputs.grad.data\n",
    "    # perturbed_inputs = torch.clamp(inputs + epsilon * torch.sign(inputs_grad), 0, 1)\n",
    "    # perturbed_inputs = perturbed_inputs.detach()\n",
    "\n",
    "    # # Perform forward pass with perturbed inputs\n",
    "    # outputs = model_ft(perturbed_inputs)\n",
    "    # loss = criterion(outputs, labels)\n",
    "    # loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    _, predicted = outputs.max(1)\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  train_loss = running_loss/len(train_loader)     # Calculating the mean of training loss\n",
    "  accu = 100.*correct/total                       # Calculating the accuracy\n",
    "\n",
    "  train_accu.append(accu)\n",
    "  train_losses.append(train_loss)\n",
    "  print('Train Loss: %.3f | Accuracy: %.3f'%(train_loss,accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "eVdTbFgifCfi"
   },
   "outputs": [],
   "source": [
    "  # Validation\n",
    "def eval_val(epoch):\n",
    "    model_ft.eval()\n",
    "    wrong_predictions = []\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(val_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Get predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Find wrong predictions\n",
    "        for j in range(len(predicted)):\n",
    "          if predicted[j] != labels[j]:\n",
    "              wrong_predictions.append({\n",
    "                  'input': inputs[j],\n",
    "                  'predicted_label': predicted[j].item(),\n",
    "                  'true_label': labels[j].item()\n",
    "              })\n",
    "        # print(val_loss)\n",
    "        val_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "    val_batch_loss = val_loss/len(val_loader)\n",
    "    val_batch_accu = 100.*correct/total                       # Calculating the accuracy\n",
    "    val_accu.append(val_batch_accu)\n",
    "    print('Val Loss: %.3f| Accuracy: %.3f' %(val_batch_loss,val_batch_accu))\n",
    "\n",
    "    print('Top 5 Wrong Predictions in Validation Set:')\n",
    "    counter = Counter([prediction['true_label'] for prediction in wrong_predictions])\n",
    "    top_wrong_predictions = counter.most_common(5)\n",
    "\n",
    "    for true_label, count in top_wrong_predictions:\n",
    "        print(f'True Label: {true_label}, Count: {count}')\n",
    "        filtered_predictions = [prediction for prediction in wrong_predictions\n",
    "                                if prediction['true_label'] == true_label][:5]\n",
    "        for prediction in filtered_predictions:\n",
    "            input_image = prediction['input']\n",
    "            predicted_label = prediction['predicted_label']\n",
    "            true_label = prediction['true_label']\n",
    "            print(f'Predicted Label: {predicted_label}, True Label: {true_label}')\n",
    "\n",
    "\n",
    "    # # Print details of wrong predictions\n",
    "    # print('Wrong Predictions in Validation Set:')\n",
    "    # for prediction in wrong_predictions:\n",
    "    #     input_image = prediction['input']\n",
    "    #     predicted_label = prediction['predicted_label']\n",
    "    #     true_label = prediction['true_label']\n",
    "    #     print(f'Predicted Label: {predicted_label}, True Label: {true_label}')\n",
    "    #     # Additional code to visualize or process the input image if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 861/861 [11:33<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.040 | Accuracy: 74.160\n",
      "Val Loss: 0.906| Accuracy: 77.654\n",
      "Top 5 Wrong Predictions in Validation Set:\n",
      "True Label: 256, Count: 45\n",
      "Predicted Label: 230, True Label: 256\n",
      "Predicted Label: 215, True Label: 256\n",
      "Predicted Label: 49, True Label: 256\n",
      "Predicted Label: 249, True Label: 256\n",
      "Predicted Label: 97, True Label: 256\n",
      "True Label: 158, Count: 18\n",
      "Predicted Label: 25, True Label: 158\n",
      "Predicted Label: 136, True Label: 158\n",
      "Predicted Label: 7, True Label: 158\n",
      "Predicted Label: 164, True Label: 158\n",
      "Predicted Label: 228, True Label: 158\n",
      "True Label: 104, Count: 17\n",
      "Predicted Label: 232, True Label: 104\n",
      "Predicted Label: 253, True Label: 104\n",
      "Predicted Label: 172, True Label: 104\n",
      "Predicted Label: 133, True Label: 104\n",
      "Predicted Label: 184, True Label: 104\n",
      "True Label: 146, Count: 17\n",
      "Predicted Label: 189, True Label: 146\n",
      "Predicted Label: 114, True Label: 146\n",
      "Predicted Label: 83, True Label: 146\n",
      "Predicted Label: 147, True Label: 146\n",
      "Predicted Label: 25, True Label: 146\n",
      "True Label: 231, Count: 12\n",
      "Predicted Label: 2, True Label: 231\n",
      "Predicted Label: 127, True Label: 231\n",
      "Predicted Label: 157, True Label: 231\n",
      "Predicted Label: 25, True Label: 231\n",
      "Predicted Label: 148, True Label: 231\n",
      "\n",
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 861/861 [09:23<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.010 | Accuracy: 74.584\n",
      "Val Loss: 0.905| Accuracy: 76.674\n",
      "Top 5 Wrong Predictions in Validation Set:\n",
      "True Label: 256, Count: 36\n",
      "Predicted Label: 28, True Label: 256\n",
      "Predicted Label: 97, True Label: 256\n",
      "Predicted Label: 186, True Label: 256\n",
      "Predicted Label: 24, True Label: 256\n",
      "Predicted Label: 77, True Label: 256\n",
      "True Label: 104, Count: 23\n",
      "Predicted Label: 27, True Label: 104\n",
      "Predicted Label: 84, True Label: 104\n",
      "Predicted Label: 55, True Label: 104\n",
      "Predicted Label: 55, True Label: 104\n",
      "Predicted Label: 150, True Label: 104\n",
      "True Label: 231, Count: 18\n",
      "Predicted Label: 34, True Label: 231\n",
      "Predicted Label: 74, True Label: 231\n",
      "Predicted Label: 158, True Label: 231\n",
      "Predicted Label: 74, True Label: 231\n",
      "Predicted Label: 221, True Label: 231\n",
      "True Label: 158, Count: 17\n",
      "Predicted Label: 256, True Label: 158\n",
      "Predicted Label: 28, True Label: 158\n",
      "Predicted Label: 89, True Label: 158\n",
      "Predicted Label: 107, True Label: 158\n",
      "Predicted Label: 97, True Label: 158\n",
      "True Label: 89, Count: 11\n",
      "Predicted Label: 37, True Label: 89\n",
      "Predicted Label: 8, True Label: 89\n",
      "Predicted Label: 63, True Label: 89\n",
      "Predicted Label: 55, True Label: 89\n",
      "Predicted Label: 8, True Label: 89\n",
      "\n",
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 861/861 [10:49<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.946 | Accuracy: 75.496\n",
      "Val Loss: 0.892| Accuracy: 77.524\n",
      "Top 5 Wrong Predictions in Validation Set:\n",
      "True Label: 256, Count: 46\n",
      "Predicted Label: 70, True Label: 256\n",
      "Predicted Label: 49, True Label: 256\n",
      "Predicted Label: 97, True Label: 256\n",
      "Predicted Label: 125, True Label: 256\n",
      "Predicted Label: 67, True Label: 256\n",
      "True Label: 3, Count: 16\n",
      "Predicted Label: 38, True Label: 3\n",
      "Predicted Label: 17, True Label: 3\n",
      "Predicted Label: 207, True Label: 3\n",
      "Predicted Label: 38, True Label: 3\n",
      "Predicted Label: 38, True Label: 3\n",
      "True Label: 231, Count: 15\n",
      "Predicted Label: 110, True Label: 231\n",
      "Predicted Label: 158, True Label: 231\n",
      "Predicted Label: 148, True Label: 231\n",
      "Predicted Label: 74, True Label: 231\n",
      "Predicted Label: 78, True Label: 231\n",
      "True Label: 104, Count: 13\n",
      "Predicted Label: 84, True Label: 104\n",
      "Predicted Label: 84, True Label: 104\n",
      "Predicted Label: 63, True Label: 104\n",
      "Predicted Label: 84, True Label: 104\n",
      "Predicted Label: 63, True Label: 104\n",
      "True Label: 95, Count: 12\n",
      "Predicted Label: 153, True Label: 95\n",
      "Predicted Label: 84, True Label: 95\n",
      "Predicted Label: 27, True Label: 95\n",
      "Predicted Label: 213, True Label: 95\n",
      "Predicted Label: 177, True Label: 95\n",
      "\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|                                                                   | 138/861 [01:38<08:35,  1.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m \u001b[38;5;66;03m# 20 run modify it later on\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m   \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m   eval_val(epoch)\n",
      "Cell \u001b[1;32mIn[46], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(inputs,labels)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Generate adversarial examples using FGSM\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# inputs.requires_grad = True\u001b[39;00m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_ft\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs,labels)  \u001b[38;5;66;03m# Calculating the loss\u001b[39;00m\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()                   \u001b[38;5;66;03m# Back Propagation for calculaing gradients and adjusting weights\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\googlenet.py:174\u001b[0m, in \u001b[0;36mGoogLeNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GoogLeNetOutputs:\n\u001b[0;32m    173\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_input(x)\n\u001b[1;32m--> 174\u001b[0m     x, aux1, aux2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     aux_defined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maux_logits\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\googlenet.py:147\u001b[0m, in \u001b[0;36mGoogLeNet._forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m    145\u001b[0m         aux2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maux2(x)\n\u001b[1;32m--> 147\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minception4e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# N x 832 x 14 x 14\u001b[39;00m\n\u001b[0;32m    149\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool4(x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\googlenet.py:227\u001b[0m, in \u001b[0;36mInception.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 227\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\googlenet.py:219\u001b[0m, in \u001b[0;36mInception._forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tensor]:\n\u001b[0;32m    218\u001b[0m     branch1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch1(x)\n\u001b[1;32m--> 219\u001b[0m     branch2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbranch2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     branch3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch3(x)\n\u001b[0;32m    221\u001b[0m     branch4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch4(x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\googlenet.py:274\u001b[0m, in \u001b[0;36mBasicConv2d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    273\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[1;32m--> 274\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mrelu(x, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:148\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[0;32m    150\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 15 # 20 run modify it later on\n",
    "for epoch in range(1, epochs+1):\n",
    "  train(epoch)\n",
    "  eval_val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqZGNTciKDRf",
    "outputId": "00fcf609-538a-4825-82b1-a4cb50c3bd94",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epochs = 30 # 20 run modify it later on\n",
    "# for epoch in range(1, epochs+1):\n",
    "#   train(epoch)\n",
    "#   eval_val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEiTRMfwydz0",
    "outputId": "38fca368-3a7c-4177-a52a-4a0bd7a3594d"
   },
   "outputs": [],
   "source": [
    "# epochs = 5 # 20 run moidfy it later on\n",
    "# for epoch in range(1, epochs+1):\n",
    "#   train(epoch)\n",
    "#   eval_val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOq1LjqPP-5Q",
    "outputId": "a3112f48-a742-4c11-8dba-53338728ad2f"
   },
   "outputs": [],
   "source": [
    "epochs = 3 # 20 run modify it later on\n",
    "for epoch in range(1, epochs+1):\n",
    "  train(epoch)\n",
    "  eval_val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlcUbFNYs7d0",
    "outputId": "a9dfce17-aa2a-4d04-ccc1-e02daf2db6dc"
   },
   "outputs": [],
   "source": [
    "# epochs = 28 # 20 run modify it later on\n",
    "# for epoch in range(1, epochs+1):\n",
    "#   train(epoch)\n",
    "#   eval_val(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbF1RIZMSf36"
   },
   "source": [
    "Validatation data sets as well - todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAZSUyfrO_4y"
   },
   "source": [
    "Hyper Parameters = epcoh, learning rate,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "XDxPernlKDU6"
   },
   "outputs": [],
   "source": [
    "PATH = 'CalTech-256-GoogleNet_v302_2307.pth'\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "oGnqhmQwKDWv",
    "outputId": "98526e80-6ab8-4588-f00b-021a865a305d"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_accu,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "HyvbQU17P5-a",
    "outputId": "029058d8-646e-4cf8-d292-444d60471de5"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train'])\n",
    "plt.title('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "hgq_S-MOP_ZZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='CalTech-256-GoogleNet_v302_2307.pth'\n",
    "model_ft.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "85hE9-shP_nw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "pd4qBH9TRFPU"
   },
   "outputs": [],
   "source": [
    "# Loading the train dataset\n",
    "test_batch_size = 1\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=test_batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "pZyKOwhQP_rq"
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i,data in enumerate(test_loader):\n",
    "  input,_ = data\n",
    "  output = model_ft(input.to(device))\n",
    "  # print(output)\n",
    "  pred = torch.max(output,dim=1)\n",
    "  # print(pred)\n",
    "  predictions.append(total_dataset.classes[pred.indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "HGZlHUr7QAHm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print([(x[0].split(\"/\",3)[2]).split('\\\\',1)[1].replace('\\\\','/') for x in list(test_loader.dataset.imgs)])\n",
    "# test_loader.dataset.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "ExS0RVcGP_-d"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['img_path'] = pd.Series([(x[0].split(\"/\",3)[2]).split('\\\\',1)[1].replace('\\\\','/') for x in list(test_loader.dataset.imgs)])\n",
    "results['label'] = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Watch-101\n",
       "1           Watch-101\n",
       "2       American-Flag\n",
       "3                Toad\n",
       "4                Toad\n",
       "            ...      \n",
       "9172             Toad\n",
       "9173             Toad\n",
       "9174             Toad\n",
       "9175             Toad\n",
       "9176             Toad\n",
       "Name: label, Length: 9177, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['label'] = results['label'].apply(lambda x: x.split('.')[1].title())\n",
    "results['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "HsAh3OJKQATl"
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"Group11_Kaggle2_Submission_v302_2307.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "YvUUC1TMP52C"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/1.jpg</td>\n",
       "      <td>240.watch-101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/10.jpg</td>\n",
       "      <td>240.watch-101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/100.jpg</td>\n",
       "      <td>002.american-flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/1000.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/1001.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test/1002.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test/1003.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test/1004.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test/1005.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test/1006.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test/1007.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test/1008.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test/1009.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test/101.jpg</td>\n",
       "      <td>002.american-flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test/1010.jpg</td>\n",
       "      <td>256.toad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_path              label\n",
       "0      test/1.jpg      240.watch-101\n",
       "1     test/10.jpg      240.watch-101\n",
       "2    test/100.jpg  002.american-flag\n",
       "3   test/1000.jpg           256.toad\n",
       "4   test/1001.jpg           256.toad\n",
       "5   test/1002.jpg           256.toad\n",
       "6   test/1003.jpg           256.toad\n",
       "7   test/1004.jpg           256.toad\n",
       "8   test/1005.jpg           256.toad\n",
       "9   test/1006.jpg           256.toad\n",
       "10  test/1007.jpg           256.toad\n",
       "11  test/1008.jpg           256.toad\n",
       "12  test/1009.jpg           256.toad\n",
       "13   test/101.jpg  002.american-flag\n",
       "14  test/1010.jpg           256.toad"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0owSLS1CP5sp"
   },
   "outputs": [],
   "source": [
    "# results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7agh3hOOKg2"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "# files.download('Group4_Pred_Submission_v75_lC_withques.csv')\n",
    "files.download('Group11_Kaggle2_Submission_v302_2107.csv')\n",
    "files.download('/content/CalTech-256-GoogleNet_v302_2107.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoNCJlnVOLqk"
   },
   "outputs": [],
   "source": [
    "# submit the file to kaggle\n",
    "# !kaggle competitions submit classification-of-caltech-256-images -f Group11_Kaggle2_Submission_v4_adv.csv -m \"Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtQPtxkwP5jh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XRDKfmeP5Zm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08BZwhmBP4BY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cu_y-HeKDZh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdQY-dzZeqWm"
   },
   "source": [
    "#### Visualize the sample images of each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCgAcqdGewsb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkOr1nhNT5yD"
   },
   "source": [
    "### **Stage 2:** Build and train the CNN model using Keras/Pytorch (5 points)\n",
    "\n",
    "You can train the CNN model and Pre-trained model and then compare the model performance on the kaggle testset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjGEBM5BFeS8"
   },
   "source": [
    "### Transfer learning\n",
    "\n",
    "Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem.\n",
    "\n",
    "A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task.\n",
    "\n",
    "The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1ZKm2M2FeTI"
   },
   "source": [
    "#### Use the pre-trained models\n",
    "\n",
    "* Load the pre-trained model\n",
    "* Train and evaluate the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHP1TsTFbUwM"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-O0Jx99UhmI"
   },
   "source": [
    "###   **Stage 3**: Evaluate the Model and get model predictions on the Kaggle testset (2 Points)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sw9qtXxaahOt"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBIA1sbLByIL"
   },
   "source": [
    "### Report Analysis\n",
    "\n",
    "- Compare the accuracies for the Pre-trained vs CNN models\n",
    "- What process was followed to tune the hyperparameters?\n",
    "- Plot the confusion matrix in terms of the misclassifications"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
